{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt-2-playground_Impactful_DS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI-HVDbQS9dF",
        "colab_type": "text"
      },
      "source": [
        "# GPT-2 Playground (Modified for Impactful Data Science)\n",
        "\n",
        "## Background\n",
        "In this Jupyter notebook you can play around with of **Open AI's GPT-2** Language Model from the paper **[Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)**. You'll be able to choose between the small (**117M** parameters) , medium (**345M** parameters), large (**774M** parameters) and XL versions (**1.5B** parameters) version of GPT-2.  \n",
        "\n",
        "According to the authors, the GPT-2 algorithm was trained on the task of *language modeling*--- which tests a program's ability to predict the next word in a given sentence--by ingesting huge numbers of articles, blogs, and websites. By using just this data it achieved state-of-the-art scores on a number of unseen language tests, an achievement known as *zero-shot learning.* It can also perform other writing-related tasks, like translating text from one language to another, summarizing long articles, and answering trivia questions.\n",
        "\n",
        "Open AI decided not to release the dataset, training code, or the full GPT-2 model weights. This is due to the concerns about large language models being used to generate deceptive, biased, or abusive language at scale. Some examples of the applications of these models for malicious purposes are:\n",
        "* Generate misleading news articles\n",
        "* Impersonate others online\n",
        "* Automate the production of abusive or faked content to post on social media\n",
        "* Automate the production of spam/phishing content\n",
        "\n",
        "As one can imagine, this combined with recent advances in generation of synthetic imagery, audio, and video implies that it's never been easier to create fake content and spread disinformation at scale. The public at large will need to become more skeptical of the content they consume online. \n",
        "\n",
        "\n",
        "## Steps\n",
        "Before starting, is recommended to set *Runtime Type* to *GPU* on the top menu bar.\n",
        "\n",
        "\n",
        "###1. Installation\n",
        "Clone the repo, install dependencies, and download the model weights. \n",
        "\n",
        "You can choose between the small 117M, medium 345M, large 774M model, xl 1.5B model or all of them.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKqlSCrpS9dH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/ilopezfr/gpt-2/\n",
        "import os\n",
        "os.chdir('gpt-2')\n",
        "!python download_model.py 117M\n",
        "!python download_model.py 345M\n",
        "\n",
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAyrz11CWmZI",
        "colab_type": "text"
      },
      "source": [
        "## Conditional sample generation\n",
        "\n",
        "To generate conditional samples from the small model:\n",
        "```\n",
        "!python3 src/interactive_conditional_samples.py\n",
        "```\n",
        "It comes with a few flags available, with a default value: \n",
        "-  `model_name = '117M' ` : choose between 117M and 345M models. By default is 117M. \n",
        "- `seed = None`  || a random value is generated unless specified. give a specific integer value if you want to reproduce same results in the future.\n",
        "- `nsamples = 1`     ||  specify the number of samples you want to print\n",
        "- `length = None`   ||  number of tokens (words) to print on each sample.\n",
        "- `batch_size= 1`  ||  how many inputs you want to process simultaneously. *only affects speed/memory* \n",
        "- `temperature = 1`  ||  float between 0 and 1. scales logits before sampling prior to softmax. higher temperature results in more random completions.\n",
        "- `top_k = 0`   ||  Integer value controlling diversity.  Truncates the set of logits considered to those with the highest values. 1 means only 1 word is considered for each step (token), resulting in deterministic completions. 40 means 40 words are considered at each step. 0 (default) is a special setting meaning no restrictions. 40 generally is a good value.\n",
        "\n",
        "\n",
        "\n",
        "The authors tested the model performance on a few different language tasks, including **reading comprehension, text completion, summarization, translation, and question-answering.**\n",
        "\n",
        "Below are a few examples selected to test the aforementioned behaviors:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfskdff44QlD",
        "colab_type": "text"
      },
      "source": [
        "### 1. Text Completion\n",
        "\n",
        "- Context: random unseen text\n",
        "\n",
        "Sample prompt 1: \n",
        "```\n",
        "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
        "```\n",
        "\n",
        "Sample prompt 2: ([*Voight-Kampff test*](https://www.youtube.com/watch?v=Umc9ezAyJv0))\n",
        "\n",
        "```\n",
        "You're in a desert, walking along in the sand, when all of a sudden you look down and see a tortoise, Leon. It's crawling toward you. You reach down, you flip the tortoise over on its back. The tortoise lays on its back, its belly baking in the hot sun, beating its legs trying to turn itself over, but it can’t, not without your help. But you’re not helping. Why is that? \n",
        "```\n",
        "\n",
        "Sample prompt 3:\n",
        "```\n",
        "I've seen things you people wouldn't believe. Attack ships on fire off the shoulder of Orion. I watched C-beams glitter in the dark near the Tannhäuser Gate. All those moments will be lost in time, like tears in rain. Time to die.\n",
        "```\n",
        "\n",
        "Sample prompt 4:\n",
        "```\n",
        "Outfit 1: Typical This pairing was the first outfit I thought of when I bought the shoes. It’s like a summer version of this Jake Grantham outfit; in fact, my shoes are close to the colors of his Nike Racers! Instead of a heavy Harris Tweed jacket and denim shirt, I’m wearing a cotton DB jacket and and a linen shirt. Both fabrics (in these colors) are an absolute must for summer, as they go with both dark and and light pants! As you can see, they pair wonderfully with the dark jeans and shoes. It’s a pseudo menswear/prep outfit. Overall, this is a very casual outfit which is why I paired my sneakers with it. I’m not about wearing a full wool suit with sneakers (as GQ shows a lot) but I’m definitely open to keeping things casual, like this cotton DB. Casual fabrics are key to pulling off your sneakers in a dressed down menswear outfit. I’d even suggest to wear these sneakers with a khaki chino suit or a white linen suit. Just be sure to ditch the tie or wear a tee or polo; wearing a tie with sneakers is a bit too much \n",
        "```\n",
        "Sample prompt 5:\n",
        "```\n",
        "- Some of the most glorious historical attractions in Spain date from the period of Muslim rule, including The Mezquita, built as the Great Mosque of Cordoba and the Medina Azahara, also in Cordoba, the Palace of al-Andalus; and the Alhambra in Granada, a splendid, intact palace.\n",
        "```\n",
        "Sample prompt 6:\n",
        "```\n",
        "How can Artificial Intelligence be dangerous? Most researchers agree that a superintelligent AI is unlikely to exhibit human emotions like love or hate, and that there is no reason to expect AI to become intentionally benevolent or malevolent. Instead, when considering how AI might become a risk, experts think two scenarios most likely:\n",
        "```\n",
        "Sample prompt 7:\n",
        "```\n",
        "Our solar system consists of the inner and outer planets, separated by an asteroid belt. It has \n",
        "```\n",
        "Sample prompt 8:\n",
        "```\n",
        "The 10 best foods are: 1. Serrano Ham 2. Manchego Cheese 3.  \n",
        "```\n",
        "Sample prompt 9:\n",
        "```\n",
        "Real Madrid boss Santiago Solari admitted his team put in a 'weak performance' in their 1-0 Copa del Rey loss to local rivals Leganes. Despite losing the game, Los Blancos will progress to the quarter final stages of the tournament, winning the tie 3-1 on aggregate thanks to a 3-0 victory in the first leg. \"It was a difficult game, but the performance was weak,\" Real Madrid boss Santi Solari on the\n",
        "```\n",
        "Sample prompt 10:\n",
        "```\n",
        "Roses are read, violets are blue,\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QIdaQn5WkSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --model_name='345M' --nsamples=2 --top_k=40 --temperature=.80"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKWlvlQbrtef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --model_name='345M'  --nsamples=2 --top_k=100 --temperature=1"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}